{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9fc9333",
   "metadata": {},
   "source": [
    "# Music Genre Classification using Neural Network\n",
    "This notebook builds a neural network to classify music genres based on MFCC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "import platform\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9297873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable GPU acceleration (Metal for macOS, CUDA for PC, fallback to CPU)\n",
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        for device in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(device, True)\n",
    "        if tf.test.is_built_with_cuda():\n",
    "            print(f\"CUDA is enabled. Using GPU(s) with CUDA: {physical_devices}\")\n",
    "        elif platform.system() == 'Darwin':\n",
    "            print(f\"Metal is enabled. Using Metal-enabled GPU on macOS: {physical_devices}\")\n",
    "        else:\n",
    "            print(f\"GPU detected but neither CUDA nor Metal is enabled: {physical_devices}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error enabling GPU acceleration: {e}\")\n",
    "else:\n",
    "    print(\"No GPU found. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1515c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MFCC data\n",
    "mfcc_df = utils.load_mfcc_data()\n",
    "labels = pd.read_csv('project_data/tracks.csv')['genre']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Drop non-numeric columns\n",
    "mfcc_df = mfcc_df.drop(columns=['file_name'])\n",
    "\n",
    "# Flatten multi-index columns and scale features\n",
    "mfcc_df.columns = ['_'.join(map(str, col)) for col in mfcc_df.columns]\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(mfcc_df)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c796f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add batch normalization and modify the neural network\n",
    "model = Sequential([\n",
    "    Dense(256, input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.3),\n",
    "    Dense(128),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(np.unique(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with a learning rate scheduler\n",
    "initial_lr = 0.001\n",
    "lr_schedule = LearningRateScheduler(lambda epoch: initial_lr * 0.95 ** epoch)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=initial_lr),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[lr_schedule, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b223cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864714a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb43bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display test data and predictions\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "for i in range(10):  # Display the first 10 test samples\n",
    "    print(f\"Test Sample {i}: True Label = {label_encoder.inverse_transform([y_test[i]])[0]}, Predicted Label = {label_encoder.inverse_transform([predicted_classes[i]])[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
